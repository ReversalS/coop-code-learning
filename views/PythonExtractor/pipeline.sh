#!/bin/bash

# 1. extract asts & source at a function scale

# 2. divide the dataset into `train`, `eval`, `test`

# 3. tensorize each dataset, according to the selected strategy (currently path-context, tokenized-source, batch-tree. fine-grained-path-context to be added)

